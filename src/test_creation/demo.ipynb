{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c1ead7-9d5b-4414-80e2-07092ba180ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0a59a9-185c-4f17-a0dd-fa2534958ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:38<00:00, 12.94s/it]\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "checklist = Checklist('../../checklist/checklist_sys.csv', checklist_format=ChecklistFormat.CSV)\n",
    "extractor = PythonTestFileExtractor(Repository('../../data/raw/openja/lightfm_demo'))\n",
    "\n",
    "evaluator = TestEvaluator(llm, extractor, checklist)\n",
    "response = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5887705f-9308-4c7c-aef2-9571d3c8b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "                                                     is_Satisfied  \\\n",
      "ID  Title                                                           \n",
      "2.1 Test Data Fetching and File Reading                       0.0   \n",
      "3.1 Validate Data Shape and Values                            0.0   \n",
      "3.2 Check for Duplicate Records in Data                       0.0   \n",
      "4.1 Verify Data Split Proportion                              0.5   \n",
      "5.1 Test Model Output Shape                                   0.5   \n",
      "6.1 Verify Evaluation Metrics Implementation                  0.5   \n",
      "6.2 Evaluate Model's Performance Against Thresholds           0.0   \n",
      "8.1 Validate Outliers Detection and Handling                  0.0   \n",
      "\n",
      "                                                     n_files_tested  \n",
      "ID  Title                                                            \n",
      "2.1 Test Data Fetching and File Reading                           3  \n",
      "3.1 Validate Data Shape and Values                                3  \n",
      "3.2 Check for Duplicate Records in Data                           3  \n",
      "4.1 Verify Data Split Proportion                                  3  \n",
      "5.1 Test Model Output Shape                                       3  \n",
      "6.1 Verify Evaluation Metrics Implementation                      3  \n",
      "6.2 Evaluate Model's Performance Against Thresholds               3  \n",
      "8.1 Validate Outliers Detection and Handling                      3  \n",
      "\n",
      "Score: 1.5/8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = ResponseParser(response)\n",
    "parser.get_completeness_score(verbose=True)\n",
    "parser.export_evaluation_report('report.html', 'html', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457726d8-b0e7-4017-9676-6dba16b18eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test-creation]",
   "language": "python",
   "name": "conda-env-test-creation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
